{"class":"org.apache.spark.ml.feature.RegexTokenizer","timestamp":1712947517641,"sparkVersion":"3.5.1","uid":"RegexTokenizer_2b5bb6d07c7e","paramMap":{"outputCol":"words","inputCol":"text"},"defaultParamMap":{"outputCol":"RegexTokenizer_2b5bb6d07c7e__output","gaps":true,"toLowercase":true,"pattern":"\\s+","minTokenLength":1}}
